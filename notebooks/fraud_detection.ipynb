{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credit Card Fraud Detection\n",
    "\n",
    "## Objective: Identify Fraudulent Transactions\n",
    "\n",
    "### Challenge: Imbalanced Dataset (99.8% Normal, 0.2% Fraud)\n",
    "\n",
    "### Models:\n",
    "- Logistic Regression\n",
    "- Random Forest\n",
    "- XGBoost\n",
    "\n",
    "### Solutions for Imbalanced Data:\n",
    "- SMOTE (Synthetic Minority Over-sampling Technique)\n",
    "- Random Undersampling\n",
    "- Class Weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('Set2')\n",
    "\n",
    "# Import custom modules\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from src.data_loader import load_data, preprocess_data, split_data, get_data_summary\n",
    "from src.imbalance_handlers import apply_smote, apply_undersampling, get_class_weights, apply_smote_tomek\n",
    "from src.models import train_logistic_regression, train_random_forest, train_xgboost, evaluate_model, compare_models\n",
    "from src.visualization import (plot_class_distribution, plot_confusion_matrix, plot_roc_curves,\n",
    "                               plot_precision_recall_curves, plot_feature_importance, \n",
    "                               plot_metrics_comparison, plot_sampling_comparison)\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load and Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "# Download from: https://www.kaggle.com/mlg-ulb/creditcardfraud\n",
    "# Place creditcard.csv in the data folder\n",
    "\n",
    "DATA_PATH = '../data/creditcard.csv'\n",
    "\n",
    "try:\n",
    "    df = load_data(DATA_PATH)\n",
    "except FileNotFoundError:\n",
    "    print(\"Please download the dataset from Kaggle and place it in the data folder.\")\n",
    "    print(\"URL: https://www.kaggle.com/mlg-ulb/creditcardfraud\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display basic info\n",
    "print(\"Dataset Shape:\", df.shape)\n",
    "print(\"\\nColumn Types:\")\n",
    "print(df.dtypes)\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data summary\n",
    "summary = get_data_summary(df)\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"DATASET SUMMARY\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Total Transactions: {summary['total_transactions']:,}\")\n",
    "print(f\"Normal Transactions: {summary['normal_transactions']:,} ({summary['normal_percentage']:.2f}%)\")\n",
    "print(f\"Fraud Transactions: {summary['fraud_transactions']:,} ({summary['fraud_percentage']:.2f}%)\")\n",
    "print(f\"Imbalance Ratio: {summary['imbalance_ratio']:.0f}:1\")\n",
    "print(f\"Missing Values: {summary['missing_values']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical description\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot class distribution\n",
    "fig = plot_class_distribution(df['Class'], \"Transaction Class Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of Amount by Class\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Normal transactions\n",
    "df[df['Class'] == 0]['Amount'].hist(bins=50, ax=axes[0], color='#2ecc71', edgecolor='black')\n",
    "axes[0].set_title('Amount Distribution - Normal Transactions')\n",
    "axes[0].set_xlabel('Amount')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "\n",
    "# Fraud transactions\n",
    "df[df['Class'] == 1]['Amount'].hist(bins=50, ax=axes[1], color='#e74c3c', edgecolor='black')\n",
    "axes[1].set_title('Amount Distribution - Fraud Transactions')\n",
    "axes[1].set_xlabel('Amount')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time distribution\n",
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "\n",
    "ax.hist(df[df['Class'] == 0]['Time'], bins=50, alpha=0.7, label='Normal', color='#2ecc71')\n",
    "ax.hist(df[df['Class'] == 1]['Time'], bins=50, alpha=0.7, label='Fraud', color='#e74c3c')\n",
    "ax.set_title('Transaction Time Distribution')\n",
    "ax.set_xlabel('Time (seconds)')\n",
    "ax.set_ylabel('Frequency')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation heatmap for selected features\n",
    "fig, ax = plt.subplots(figsize=(16, 12))\n",
    "corr_matrix = df.corr()\n",
    "mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
    "sns.heatmap(corr_matrix, mask=mask, cmap='coolwarm', center=0, \n",
    "            square=True, linewidths=0.5, ax=ax, cbar_kws={'shrink': 0.8})\n",
    "ax.set_title('Feature Correlation Heatmap')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation with target variable\n",
    "corr_with_class = df.corr()['Class'].drop('Class').sort_values(key=abs, ascending=False)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "colors = ['#e74c3c' if x < 0 else '#2ecc71' for x in corr_with_class.values]\n",
    "corr_with_class.plot(kind='barh', ax=ax, color=colors, edgecolor='black')\n",
    "ax.set_title('Feature Correlation with Fraud (Class)')\n",
    "ax.set_xlabel('Correlation Coefficient')\n",
    "ax.axvline(x=0, color='black', linestyle='-', linewidth=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess data (scale Amount and Time)\n",
    "df_processed = preprocess_data(df, scale_amount=True, scale_time=True)\n",
    "print(\"Processed features:\", list(df_processed.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "X_train, X_test, y_train, y_test = split_data(df_processed, target_col='Class', test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Handling Imbalanced Data\n",
    "\n",
    "### 5.1 SMOTE (Synthetic Minority Over-sampling Technique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply SMOTE\n",
    "X_train_smote, y_train_smote = apply_smote(X_train, y_train, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Random Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Undersampling\n",
    "X_train_under, y_train_under = apply_undersampling(X_train, y_train, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Class Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate class weights\n",
    "class_weights = get_class_weights(y_train, weight_type='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare sampling methods\n",
    "sampling_results = {\n",
    "    'Original': (X_train, y_train),\n",
    "    'SMOTE': (X_train_smote, y_train_smote),\n",
    "    'Undersampling': (X_train_under, y_train_under)\n",
    "}\n",
    "\n",
    "fig = plot_sampling_comparison(sampling_results)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Training\n",
    "\n",
    "### 6.1 Baseline Models (No Resampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train baseline models (no resampling, no class weights)\n",
    "print(\"Training Baseline Models (Original Data)...\\n\")\n",
    "\n",
    "lr_baseline = train_logistic_regression(X_train, y_train)\n",
    "rf_baseline = train_random_forest(X_train, y_train)\n",
    "xgb_baseline = train_xgboost(X_train, y_train, scale_pos_weight=1)  # No weight adjustment\n",
    "\n",
    "print(\"Baseline models trained!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate baseline models\n",
    "baseline_results = {\n",
    "    'LR (Baseline)': evaluate_model(lr_baseline, X_test, y_test, 'Logistic Regression (Baseline)'),\n",
    "    'RF (Baseline)': evaluate_model(rf_baseline, X_test, y_test, 'Random Forest (Baseline)'),\n",
    "    'XGB (Baseline)': evaluate_model(xgb_baseline, X_test, y_test, 'XGBoost (Baseline)')\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Models with SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train models on SMOTE data\n",
    "print(\"Training Models with SMOTE...\\n\")\n",
    "\n",
    "lr_smote = train_logistic_regression(X_train_smote, y_train_smote)\n",
    "rf_smote = train_random_forest(X_train_smote, y_train_smote)\n",
    "xgb_smote = train_xgboost(X_train_smote, y_train_smote, scale_pos_weight=1)\n",
    "\n",
    "print(\"SMOTE models trained!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate SMOTE models\n",
    "smote_results = {\n",
    "    'LR (SMOTE)': evaluate_model(lr_smote, X_test, y_test, 'Logistic Regression (SMOTE)'),\n",
    "    'RF (SMOTE)': evaluate_model(rf_smote, X_test, y_test, 'Random Forest (SMOTE)'),\n",
    "    'XGB (SMOTE)': evaluate_model(xgb_smote, X_test, y_test, 'XGBoost (SMOTE)')\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Models with Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train models on Undersampled data\n",
    "print(\"Training Models with Undersampling...\\n\")\n",
    "\n",
    "lr_under = train_logistic_regression(X_train_under, y_train_under)\n",
    "rf_under = train_random_forest(X_train_under, y_train_under)\n",
    "xgb_under = train_xgboost(X_train_under, y_train_under, scale_pos_weight=1)\n",
    "\n",
    "print(\"Undersampling models trained!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Undersampling models\n",
    "under_results = {\n",
    "    'LR (Under)': evaluate_model(lr_under, X_test, y_test, 'Logistic Regression (Undersampling)'),\n",
    "    'RF (Under)': evaluate_model(rf_under, X_test, y_test, 'Random Forest (Undersampling)'),\n",
    "    'XGB (Under)': evaluate_model(xgb_under, X_test, y_test, 'XGBoost (Undersampling)')\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 Models with Class Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train models with class weights\n",
    "print(\"Training Models with Class Weights...\\n\")\n",
    "\n",
    "lr_weighted = train_logistic_regression(X_train, y_train, class_weight='balanced')\n",
    "rf_weighted = train_random_forest(X_train, y_train, class_weight='balanced')\n",
    "xgb_weighted = train_xgboost(X_train, y_train)  # Auto-calculates scale_pos_weight\n",
    "\n",
    "print(\"Weighted models trained!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Weighted models\n",
    "weighted_results = {\n",
    "    'LR (Weighted)': evaluate_model(lr_weighted, X_test, y_test, 'Logistic Regression (Weighted)'),\n",
    "    'RF (Weighted)': evaluate_model(rf_weighted, X_test, y_test, 'Random Forest (Weighted)'),\n",
    "    'XGB (Weighted)': evaluate_model(xgb_weighted, X_test, y_test, 'XGBoost (Weighted)')\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all results\n",
    "all_results = {**baseline_results, **smote_results, **under_results, **weighted_results}\n",
    "\n",
    "# Create comparison DataFrame\n",
    "comparison_data = []\n",
    "for name, metrics in all_results.items():\n",
    "    comparison_data.append({\n",
    "        'Model': name,\n",
    "        'Accuracy': metrics['accuracy'],\n",
    "        'Precision': metrics['precision'],\n",
    "        'Recall': metrics['recall'],\n",
    "        'F1-Score': metrics['f1_score'],\n",
    "        'ROC-AUC': metrics['roc_auc'],\n",
    "        'Avg Precision': metrics['avg_precision']\n",
    "    })\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "comparison_df = comparison_df.sort_values('F1-Score', ascending=False)\n",
    "print(\"\\nModel Comparison (Sorted by F1-Score):\")\n",
    "comparison_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot metrics comparison for best models (one from each approach)\n",
    "best_models = {\n",
    "    'XGB (Baseline)': baseline_results['XGB (Baseline)'],\n",
    "    'XGB (SMOTE)': smote_results['XGB (SMOTE)'],\n",
    "    'XGB (Under)': under_results['XGB (Under)'],\n",
    "    'XGB (Weighted)': weighted_results['XGB (Weighted)']\n",
    "}\n",
    "\n",
    "fig = plot_metrics_comparison(best_models)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC Curves comparison\n",
    "fig = plot_roc_curves(best_models, y_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision-Recall Curves comparison\n",
    "fig = plot_precision_recall_curves(best_models, y_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Best Model Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find best model based on F1-Score\n",
    "best_model_name = comparison_df.iloc[0]['Model']\n",
    "print(f\"Best Model: {best_model_name}\")\n",
    "print(f\"F1-Score: {comparison_df.iloc[0]['F1-Score']:.4f}\")\n",
    "print(f\"Recall: {comparison_df.iloc[0]['Recall']:.4f}\")\n",
    "print(f\"ROC-AUC: {comparison_df.iloc[0]['ROC-AUC']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix for best model\n",
    "best_results = all_results[best_model_name]\n",
    "fig = plot_confusion_matrix(y_test, best_results['y_pred'], f\"Confusion Matrix - {best_model_name}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance (for XGBoost model)\n",
    "feature_names = X_train.columns.tolist()\n",
    "fig = plot_feature_importance(xgb_weighted, feature_names, top_n=20, \n",
    "                              title=\"Feature Importance - XGBoost (Weighted)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Summary and Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"CREDIT CARD FRAUD DETECTION - SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\n1. DATASET CHARACTERISTICS:\")\n",
    "print(f\"   - Total Transactions: {summary['total_transactions']:,}\")\n",
    "print(f\"   - Fraud Rate: {summary['fraud_percentage']:.3f}%\")\n",
    "print(f\"   - Imbalance Ratio: {summary['imbalance_ratio']:.0f}:1\")\n",
    "\n",
    "print(\"\\n2. IMBALANCE HANDLING TECHNIQUES TESTED:\")\n",
    "print(\"   - SMOTE (Synthetic Minority Over-sampling)\")\n",
    "print(\"   - Random Undersampling\")\n",
    "print(\"   - Class Weights\")\n",
    "\n",
    "print(\"\\n3. MODELS COMPARED:\")\n",
    "print(\"   - Logistic Regression\")\n",
    "print(\"   - Random Forest\")\n",
    "print(\"   - XGBoost\")\n",
    "\n",
    "print(\"\\n4. KEY FINDINGS:\")\n",
    "print(f\"   - Best Model: {best_model_name}\")\n",
    "print(f\"   - Best F1-Score: {comparison_df.iloc[0]['F1-Score']:.4f}\")\n",
    "print(f\"   - Best Recall: {comparison_df.iloc[0]['Recall']:.4f}\")\n",
    "\n",
    "print(\"\\n5. RECOMMENDATIONS:\")\n",
    "print(\"   - For fraud detection, prioritize RECALL to catch more frauds\")\n",
    "print(\"   - Use class weights or SMOTE for better minority class detection\")\n",
    "print(\"   - XGBoost with class weights provides best balance\")\n",
    "print(\"   - Consider business cost of false positives vs false negatives\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display final comparison table\n",
    "print(\"\\nFINAL MODEL COMPARISON:\")\n",
    "comparison_df.style.background_gradient(cmap='RdYlGn', subset=['F1-Score', 'Recall', 'ROC-AUC'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
